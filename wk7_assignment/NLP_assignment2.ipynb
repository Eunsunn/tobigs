{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 id=\"1.-데이터-크롤링\">1. 데이터 크롤링<a class=\"anchor-link\" href=\"#1.-데이터-크롤링\">¶</a></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"동네-마카롱-트위터-크롤링\">동네 마카롱 트위터 크롤링<a class=\"anchor-link\" href=\"#동네-마카롱-트위터-크롤링\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from twitterscraper import logging\n",
    "from twitterscraper import main\n",
    "from twitterscraper import query\n",
    "from twitterscraper import tweet\n",
    "import pandas as pd\n",
    "import codecs, json\n",
    "from twitterscraper import query_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import random\n",
    "import requests\n",
    "import datetime as dt\n",
    "import json\n",
    "from functools import partial\n",
    "from multiprocessing.pool import Pool\n",
    "\n",
    "from twitterscraper.tweet import Tweet\n",
    "#from twitterscraper.logging import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  query_tweets(query, limit = None, begindate = dt.date(2006,3,21), enddate=dt.date.today(), poolsize=20, lang='')\n",
    "if __name__ == '__main__':\n",
    "    list_of_tweets = query_tweets(\"정릉 마카롱\", begindate = dt.date(2018,1,1) , poolsize =50)\n",
    "\n",
    "    #print the retrieved tweets to the screen:\n",
    "    for tweet in query_tweets(\"정릉 마카롱\", begindate = dt.date(2019,3,10), poolsize = 50):\n",
    "        print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "for i in range(len(list_of_tweets)) :\n",
    "    text += [list_of_tweets[i].text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 id=\"2.-데이터-전처리\">2. 데이터 전처리<a class=\"anchor-link\" href=\"#2.-데이터-전처리\">¶</a></h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#불필요한 영어, 특수문자 제거\n",
    "import re\n",
    "data = []\n",
    "for i in text:\n",
    "    j = re.sub('[a-zA-Z]' , '', i)\n",
    "    j = re.sub('[\\{\\}\\[\\]\\/?.,;:|\\)*~`!^…\\n\\-_+<>@\\#$%&\\\\\\=\\(\\'\\\"]','', j)\n",
    "    data.append(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 id=\"3.-Tokenize\">3. Tokenize<a class=\"anchor-link\" href=\"#3.-Tokenize\">¶</a></h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import *\n",
    "twitter = Twitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for i in data:\n",
    "    word = twitter.pos(i)[0]\n",
    "    word_type = twitter.pos(i)[1]\n",
    "    corpus.append(['/'.join(p) for p in twitter.pos(i) if p[1] !=\"Josa\" and p[1] !=\"KoreanParticle\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 id=\"4.-Model\">4. Model<a class=\"anchor-link\" href=\"#4.-Model\">¶</a></h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_gram = Word2Vec(corpus, size=2, window=2, min_count=2, workers=1, iter=2000, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = skip_gram.wv.index2word #index2word : one-hot encoding\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = skip_gram.wv.vectors\n",
    "vectors #토큰들의 임베딩 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = dict(zip(words, vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#코사인 유사도로 마카롱과 유사한 상위 10개단어 보기\n",
    "skip_gram.most_similar('마카롱/Noun', topn=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "w2v_df = pd.DataFrame(vectors, columns = ['x1', 'x2'])\n",
    "w2v_df['word'] = words\n",
    "w2v_df = w2v_df[['word', 'x1', 'x2']]\n",
    "w2v_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for idx, x1, x2 in zip(range(len(w2v_df)), w2v_df['x1'], w2v_df['x2']):\n",
    "    ax.annotate(idx, (x1,x2))\n",
    "    \n",
    "PADDING = 1.0\n",
    "x_axis_min = np.amin(vectors, axis=0)[0] - PADDING\n",
    "y_axis_min = np.amin(vectors, axis=0)[1] - PADDING\n",
    "x_axis_max = np.amax(vectors, axis=0)[0] + PADDING\n",
    "y_axis_max = np.amax(vectors, axis=0)[1] + PADDING\n",
    " \n",
    "plt.xlim(x_axis_min,x_axis_max)\n",
    "plt.ylim(y_axis_min,y_axis_max)\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"코사인 유사도 상위 5번째 값인 수는 마카롱집 이름인데, 원래 이름이 수마카롱이다. \n",
    "단어를 형태소로 분리하다보니까 고유명사를 잘 인식하지 못하는 것 같지만\n",
    " 동네 마카롱 맛집 정보를 얻었다!\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
